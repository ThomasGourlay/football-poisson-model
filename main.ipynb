{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b596127c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "from scipy.stats import poisson\n",
    "from scipy.optimize import minimize\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aa98456",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Team:\n",
    "    '''\n",
    "    stores some basic information about a team\n",
    "    '''\n",
    "    name: str\n",
    "    attack: float\n",
    "    defence: float\n",
    "\n",
    "@dataclass\n",
    "class Settings:\n",
    "    '''\n",
    "    store the settings (hyperparameters) used\n",
    "    sd_movement = sd of change in team abilities between seasons\n",
    "        (higher -> team ratings are allowed to change more between seasons)\n",
    "    '''\n",
    "    sd_movement: float\n",
    "    h_adv_init: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb9b5b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_date(datestr: str) -> date:\n",
    "    '''\n",
    "    reformat date string DD/MM/YYYY into datetime date\n",
    "    '''\n",
    "    info = datestr.split(\"/\")\n",
    "    day = int(info[0])\n",
    "    month = int(info[1])\n",
    "    year = int(info[2])\n",
    "    return date(year, month, day)\n",
    "\n",
    "def calculate_season(date: date) -> int:\n",
    "    '''\n",
    "    figure out what season we are in (2023/24 season is called 2024, etc)\n",
    "    '''\n",
    "    if date.month >= 7:\n",
    "        return date.year\n",
    "    return date.year - 1\n",
    "\n",
    "\n",
    "\n",
    "def gather_matches(match_data: pd.DataFrame, team_idx: dict) -> np.ndarray:\n",
    "    '''\n",
    "    takes a dataframe of matches and converts it into a np array with just basic information\n",
    "    output: array of tuples of matches (home index, away index, home goals, away goals)\n",
    "    '''\n",
    "    match_data = match_data.copy()\n",
    "    match_data[\"h_idx\"] = match_data[\"HomeTeam\"].apply(lambda x: team_idx[x])\n",
    "    match_data[\"a_idx\"] = match_data[\"AwayTeam\"].apply(lambda x: team_idx[x])\n",
    "\n",
    "    match_data = match_data[[\"h_idx\", \"a_idx\", \"FTHG\", \"FTAG\"]]\n",
    "    matches = [tuple(i) for i in match_data.itertuples(index=False, name=None)]\n",
    "\n",
    "    return np.array(matches)\n",
    "\n",
    "def neg_log_season(theta: np.ndarray, matches_array: np.ndarray, n_teams: int) -> float:\n",
    "    '''\n",
    "    calculates the negative log likelihood of a season, given attack, defence, home adv ratings\n",
    "    vectorised for decent performance. for loops would be very slow\n",
    "    '''\n",
    "    attacks = theta[:n_teams]\n",
    "    defences = theta[n_teams:2*n_teams]\n",
    "    home_adv = theta[-1]\n",
    "\n",
    "    attacks = attacks - np.mean(attacks)  # identifiability by enforcing attacks mean=0\n",
    "\n",
    "    h_idx = matches_array[:, 0].astype(int)\n",
    "    a_idx = matches_array[:, 1].astype(int)\n",
    "    h_goals = matches_array[:, 2].astype(int)\n",
    "    a_goals = matches_array[:, 3].astype(int)\n",
    "\n",
    "    # calculate lambda param for home and away poisson distributinos\n",
    "    lam_h = np.exp(home_adv + attacks[h_idx] - defences[a_idx])\n",
    "    lam_h = np.clip(lam_h, 1e-10, 1e2)  # prevent underflow / overflow (usually unnecessary)\n",
    "\n",
    "    lam_a = np.exp(-home_adv + attacks[a_idx] - defences[h_idx])\n",
    "    lam_a = np.clip(lam_a, 1e-10, 1e2)  # prevent underflow / overflow (usually unnecessary)\n",
    "\n",
    "    # calculate log likelihood\n",
    "    log_like = poisson.logpmf(h_goals, lam_h) + poisson.logpmf(a_goals, lam_a)\n",
    "    return -np.sum(log_like)\n",
    "\n",
    "\n",
    "def p_total_over(goals: float, home_team: Team, away_team: Team, home_adv: float) -> float:\n",
    "    '''\n",
    "    calculates the probability of the total goals in a match exceeding some number\n",
    "    '''\n",
    "    lam_h = np.exp(home_adv + home_team.attack - away_team.defence)\n",
    "    lam_a = np.exp(-home_adv + away_team.attack - home_team.defence)\n",
    "    lam = lam_h + lam_a\n",
    "    prob = 1 - poisson.cdf(np.floor(goals), lam)\n",
    "    return prob\n",
    "\n",
    "def p_over(goals: float, home_team: Team, away_team: Team, home_adv: float, home_or_away: str) -> float:\n",
    "    '''\n",
    "    calculates the probability of one team's goals in a match exceeding some number\n",
    "    '''\n",
    "    if home_or_away == \"home\":\n",
    "        lam = np.exp(home_adv + home_team.attack - away_team.defence)\n",
    "        return 1 - poisson.cdf(np.floor(goals), lam)\n",
    "    lam = np.exp(-home_adv + away_team.attack - home_team.defence)\n",
    "    return 1 - poisson.cdf(lam, np.floor(goals))\n",
    "\n",
    "def log_likelihood(big_theta: np.ndarray, seasons: dict, n_teams: int, settings: Settings) -> float:\n",
    "\n",
    "    '''\n",
    "    big log likelihood function\n",
    "    '''\n",
    "    # take theta and break it into components (season by seasons ratings + home adv)\n",
    "    unique_seasons = list(seasons.keys())\n",
    "    n_seasons = len(unique_seasons)\n",
    "    thetas=dict()\n",
    "    home_adv = big_theta[-1]\n",
    "    for season in range(n_seasons):\n",
    "        curr_theta = big_theta[2*n_teams*season:2*n_teams*(season+1)]\n",
    "        curr_theta = np.append(curr_theta, home_adv)\n",
    "        thetas[unique_seasons[season]] = curr_theta\n",
    "\n",
    "    # for each season, calculate (negative) log-likelihood and add to total\n",
    "    nll = 0\n",
    "    for season in seasons.keys():\n",
    "        matches = seasons[season]\n",
    "        theta = thetas[season]\n",
    "        nll += neg_log_season(theta=theta, matches_array=matches, n_teams=n_teams)\n",
    "\n",
    "\n",
    "    # now calculate nll of change in rating between seasons\n",
    "    # stack all season ratings into array (n_seasons, n_teams)\n",
    "    attack_ratings = np.stack([big_theta[2*n_teams*season:2*n_teams*season + n_teams] for season in range(n_seasons)], axis=0)\n",
    "    defence_ratings = np.stack([big_theta[2*n_teams*season + n_teams : 2*n_teams*(season+1)] for season in range(n_seasons)], axis=0)\n",
    "\n",
    "    # find differences across seasons\n",
    "    attack_diffs = attack_ratings[1:] - attack_ratings[:-1]  # shape (n_seasons-1, n_teams)\n",
    "    defence_diffs = defence_ratings[1:] - defence_ratings[:-1]\n",
    "\n",
    "    # log-likelihood contribution from random walk\n",
    "    sd = settings.sd_movement\n",
    "    n = n_seasons - 1\n",
    "\n",
    "    # vectorised\n",
    "    rw_ll = -0.5 * n * np.log(2*np.pi) - n * np.log(sd) - np.sum(attack_diffs**2) / (2*sd**2)\n",
    "    rw_ll += -0.5 * n * np.log(2*np.pi) - n * np.log(sd) - np.sum(defence_diffs**2) / (2*sd**2)\n",
    "\n",
    "    # subtract because function returns nll\n",
    "    nll -= rw_ll\n",
    "    return nll\n",
    "\n",
    "def theta_to_df(big_theta: np.ndarray, season_matches: dict, teams: list, n_teams: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert flat theta vector into a DataFrame of team ratings per season using preprocessed data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    big_theta : np.ndarray\n",
    "        Flat array containing all attack/defence ratings for all seasons + home_adv at the end\n",
    "    season_matches : dict\n",
    "        Dictionary mapping season -> np.ndarray of matches (h_idx, a_idx, h_goals, a_goals)\n",
    "    teams : list of str\n",
    "        List of team names in order corresponding to indices in theta\n",
    "    n_teams : int\n",
    "        Number of teams\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Columns: [\"Season\", \"Team\", \"Attack\", \"Defence\"]\n",
    "        Plus a final row for home advantage\n",
    "    \"\"\"\n",
    "    home_adv = big_theta[-1]\n",
    "    rows = []\n",
    "\n",
    "    # Sort seasons so theta slices match\n",
    "    sorted_seasons = sorted(season_matches.keys())\n",
    "    n_seasons = len(sorted_seasons)\n",
    "\n",
    "    for season_idx, season in enumerate(sorted_seasons):\n",
    "        # slice out season-specific parameters\n",
    "        season_theta = big_theta[2*n_teams*season_idx : 2*n_teams*(season_idx+1)]\n",
    "        attacks = season_theta[:n_teams]\n",
    "        defences = season_theta[n_teams:2*n_teams]\n",
    "\n",
    "        # optional: mean-zero attacks for identifiability\n",
    "        attacks = attacks - np.mean(attacks)\n",
    "\n",
    "        for i, team in enumerate(teams):\n",
    "            rows.append({\n",
    "                \"Season\": season,\n",
    "                \"Team\": team,\n",
    "                \"Attack\": attacks[i],\n",
    "                \"Defence\": defences[i]\n",
    "            })\n",
    "\n",
    "    # Add home advantage row\n",
    "    rows.append({\n",
    "        \"Season\": \"All\",\n",
    "        \"Team\": \"HomeAdv\",\n",
    "        \"Attack\": home_adv,\n",
    "        \"Defence\": np.nan\n",
    "    })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n",
    "\n",
    "\n",
    "def backtest(df_ratings: pd.DataFrame, match_data: pd.DataFrame, init_pnl: float =0):\n",
    "    '''\n",
    "    a backtest that uses attacking/defensive ratings and match data to bet on\n",
    "    over/under 2.5 goals, using Bet365 odds as our book\n",
    "    omniscient in that it uses ratings that were probably calculated using future data\n",
    "    this makes it slightly unrealistic, and real returns may not be as good, if positive at all!\n",
    "\n",
    "    this function is not very optimised, so takes a few seconds to run. could be optimised if needed\n",
    "    '''\n",
    "    money = init_pnl\n",
    "    n_bets = 0\n",
    "    dates = []\n",
    "    pnl = []\n",
    "\n",
    "    # get the home advantage from the df\n",
    "    home_adv = df_ratings.loc[df_ratings[\"Team\"]==\"HomeAdv\", \"Attack\"].iloc[0]\n",
    "    for _, match in match_data.iterrows():\n",
    "        # get important information about the match\n",
    "        season = match[\"Season\"]\n",
    "        date = match[\"Date\"]\n",
    "        curr_ratings = df_ratings[df_ratings[\"Season\"]==season]\n",
    "\n",
    "        # get important information about the teams\n",
    "        h_name = match[\"HomeTeam\"]\n",
    "        h_att = curr_ratings.loc[curr_ratings[\"Team\"]==h_name, \"Attack\"].iloc[0]\n",
    "        h_def = curr_ratings.loc[curr_ratings[\"Team\"]==h_name, \"Defence\"].iloc[0]\n",
    "\n",
    "        a_name = match[\"AwayTeam\"]\n",
    "        a_att = curr_ratings.loc[curr_ratings[\"Team\"]==a_name, \"Attack\"].iloc[0]\n",
    "        a_def = curr_ratings.loc[curr_ratings[\"Team\"]==a_name, \"Defence\"].iloc[0]\n",
    "\n",
    "        # package the teams into Team dataclass\n",
    "        home_team = Team(h_name, h_att, h_def)\n",
    "        away_team = Team(a_name, a_att, a_def)\n",
    "\n",
    "        # check if the over bet is underpriced, if it is, bet\n",
    "        fair = 1/p_total_over(2.5, home_team=home_team, away_team=away_team, home_adv=home_adv)\n",
    "        odds = match[\"B365>2.5\"]\n",
    "        if fair < odds:\n",
    "\n",
    "            total = match[\"FTHG\"] + match[\"FTAG\"]\n",
    "            if total > 2.5:\n",
    "                money += odds - 1\n",
    "            else:\n",
    "                money -= 1\n",
    "            \n",
    "\n",
    "        # check if the under bet is underpriced, if it is, bet\n",
    "        fair = 1/(1-1/fair)\n",
    "        odds = match[\"B365<2.5\"]\n",
    "        if fair < odds:\n",
    "            total = match[\"FTHG\"] + match[\"FTAG\"]\n",
    "            if total < 2.5:\n",
    "                money += odds - 1\n",
    "            else:\n",
    "                money -= 1\n",
    "        pnl.append(money)\n",
    "        dates.append(date)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"pnl\": pnl,\n",
    "        \"date\": dates\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def fit_params(season_matches, n_teams, n_seasons, settings, teams):\n",
    "    theta0 = np.zeros(2*n_seasons*n_teams + 1)\n",
    "    theta0[-1] = settings.h_adv_init\n",
    "\n",
    "    res=minimize(\n",
    "        fun=log_likelihood,\n",
    "        x0=theta0,\n",
    "        args=(season_matches,n_teams,settings),\n",
    "        method=\"L-BFGS-B\"\n",
    "    )\n",
    "    ratings=res.x\n",
    "    ratings = theta_to_df(ratings, season_matches, teams, n_teams)\n",
    "    return ratings\n",
    "\n",
    "def fit_and_backtest(match_data: pd.DataFrame, settings: Settings, team_idx: dict, test_begin: date, test_end: date, init_pnl: float=0):\n",
    "    '''\n",
    "    fit up to certain date,\n",
    "    backtest after that date until test_end\n",
    "    test end should be in the same season as test_begin\n",
    "    '''\n",
    "    teams = list(team_idx.keys())\n",
    "    n_teams = len(team_idx)\n",
    "\n",
    "    match_data = match_data.copy()\n",
    "    train = match_data[match_data[\"Date\"] < test_begin]\n",
    "    test = match_data[(match_data[\"Date\"] >= test_begin) & (match_data[\"Date\"] <= test_end)]\n",
    "    seasons = dict(tuple(train.groupby(\"Season\")))\n",
    "    season_matches = {season: gather_matches(df, team_idx)\n",
    "                      for season, df in seasons.items()}\n",
    "    n_seasons = len(seasons)\n",
    "    print(f\"fitting paramaters on data up to {test_begin}\")\n",
    "    ratings = fit_params(season_matches, n_teams, n_seasons, settings, teams)\n",
    "    print(f\"testing params on data from {test_begin} until {test_end}\")\n",
    "    results = backtest(ratings, test, init_pnl)\n",
    "    final_pnl = results.iloc[-1][\"pnl\"]\n",
    "    net = final_pnl-init_pnl\n",
    "    print(f\"in this period we made net ${net:.2f}\\n\")\n",
    "    return results, final_pnl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61de2afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "preprocessing and formatting work\n",
    "'''\n",
    "\n",
    "match_data = pd.read_csv(\"EPL.csv\")\n",
    "match_data[\"Date\"] = match_data[\"Date\"].apply(make_date)            # reformat date\n",
    "\n",
    "match_data[\"Season\"] = match_data[\"Date\"].apply(calculate_season)   # figure out what season we're in\n",
    "\n",
    "match_data.sort_values(by=\"Date\",inplace=True)                      # sort data by date\n",
    "match_data = match_data.reset_index(drop=True)\n",
    "\n",
    "# Get unique teams from BOTH home and away\n",
    "home_teams = set(match_data[\"HomeTeam\"].unique())\n",
    "away_teams = set(match_data[\"AwayTeam\"].unique())\n",
    "teams = sorted(list(home_teams | away_teams))  # Union of both sets\n",
    "team_idx = {j:i for i,j in enumerate(teams)}\n",
    "\n",
    "n_teams = len(team_idx)\n",
    "\n",
    "\n",
    "seasons = dict(tuple(match_data.groupby(\"Season\"))) # split the data into seasons\n",
    "n_seasons = len(seasons)\n",
    "\n",
    "season_matches = {                                  # group the data into seasons and make them lists of tuples for vectorisation\n",
    "    season: gather_matches(df, team_idx)\n",
    "    for season, df in seasons.items()\n",
    "}\n",
    "\n",
    "settings=Settings(0.1,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8fd2a100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_half_backtest(match_data, settings, team_idx, first, last):\n",
    "    mylist=[]\n",
    "    pnl=0\n",
    "    for year in range(first,last+1):\n",
    "        start = date(year, 1, 1)\n",
    "        end = date(year,6,30)\n",
    "        results, pnl = fit_and_backtest(match_data, settings, team_idx, start, end, pnl)\n",
    "        mylist.append(results)\n",
    "    final = pd.concat(mylist)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59a42941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting paramaters on data up to 2019-01-01\n",
      "testing params on data from 2019-01-01 until 2019-06-30\n",
      "in this period we made net $12.49\n",
      "\n",
      "fitting paramaters on data up to 2020-01-01\n",
      "testing params on data from 2020-01-01 until 2020-06-30\n",
      "in this period we made net $31.24\n",
      "\n",
      "fitting paramaters on data up to 2021-01-01\n",
      "testing params on data from 2021-01-01 until 2021-06-30\n",
      "in this period we made net $9.83\n",
      "\n",
      "fitting paramaters on data up to 2022-01-01\n",
      "testing params on data from 2022-01-01 until 2022-06-30\n",
      "in this period we made net $12.68\n",
      "\n",
      "fitting paramaters on data up to 2023-01-01\n",
      "testing params on data from 2023-01-01 until 2023-06-30\n",
      "in this period we made net $9.98\n",
      "\n",
      "fitting paramaters on data up to 2024-01-01\n",
      "testing params on data from 2024-01-01 until 2024-06-30\n",
      "in this period we made net $29.47\n",
      "\n",
      "fitting paramaters on data up to 2025-01-01\n",
      "testing params on data from 2025-01-01 until 2025-06-30\n",
      "in this period we made net $-4.47\n",
      "\n",
      "fitting paramaters on data up to 2026-01-01\n",
      "testing params on data from 2026-01-01 until 2026-06-30\n",
      "in this period we made net $8.32\n",
      "\n",
      "fitting paramaters on data up to 2019-01-01\n",
      "testing params on data from 2019-01-01 until 2019-06-30\n",
      "in this period we made net $12.49\n",
      "\n",
      "fitting paramaters on data up to 2020-01-01\n",
      "testing params on data from 2020-01-01 until 2020-06-30\n",
      "in this period we made net $30.12\n",
      "\n",
      "fitting paramaters on data up to 2021-01-01\n",
      "testing params on data from 2021-01-01 until 2021-06-30\n",
      "in this period we made net $12.04\n",
      "\n",
      "fitting paramaters on data up to 2022-01-01\n",
      "testing params on data from 2022-01-01 until 2022-06-30\n",
      "in this period we made net $13.51\n",
      "\n",
      "fitting paramaters on data up to 2023-01-01\n",
      "testing params on data from 2023-01-01 until 2023-06-30\n",
      "in this period we made net $18.26\n",
      "\n",
      "fitting paramaters on data up to 2024-01-01\n",
      "testing params on data from 2024-01-01 until 2024-06-30\n",
      "in this period we made net $30.21\n",
      "\n",
      "fitting paramaters on data up to 2025-01-01\n",
      "testing params on data from 2025-01-01 until 2025-06-30\n",
      "in this period we made net $-0.62\n",
      "\n",
      "fitting paramaters on data up to 2026-01-01\n",
      "testing params on data from 2026-01-01 until 2026-06-30\n",
      "in this period we made net $5.12\n",
      "\n",
      "fitting paramaters on data up to 2019-01-01\n",
      "testing params on data from 2019-01-01 until 2019-06-30\n",
      "in this period we made net $12.49\n",
      "\n",
      "fitting paramaters on data up to 2020-01-01\n",
      "testing params on data from 2020-01-01 until 2020-06-30\n",
      "in this period we made net $27.17\n",
      "\n",
      "fitting paramaters on data up to 2021-01-01\n",
      "testing params on data from 2021-01-01 until 2021-06-30\n",
      "in this period we made net $23.62\n",
      "\n",
      "fitting paramaters on data up to 2022-01-01\n",
      "testing params on data from 2022-01-01 until 2022-06-30\n",
      "in this period we made net $14.63\n",
      "\n",
      "fitting paramaters on data up to 2023-01-01\n",
      "testing params on data from 2023-01-01 until 2023-06-30\n",
      "in this period we made net $32.47\n",
      "\n",
      "fitting paramaters on data up to 2024-01-01\n",
      "testing params on data from 2024-01-01 until 2024-06-30\n",
      "in this period we made net $36.49\n",
      "\n",
      "fitting paramaters on data up to 2025-01-01\n",
      "testing params on data from 2025-01-01 until 2025-06-30\n",
      "in this period we made net $-8.44\n",
      "\n",
      "fitting paramaters on data up to 2026-01-01\n",
      "testing params on data from 2026-01-01 until 2026-06-30\n",
      "in this period we made net $5.13\n",
      "\n",
      "fitting paramaters on data up to 2018-01-01\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "need at least one array to stack",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m point1 \u001b[38;5;241m=\u001b[39m second_half_backtest(match_data, Settings(\u001b[38;5;241m0.1\u001b[39m,\u001b[38;5;241m0.1\u001b[39m), team_idx, \u001b[38;5;241m2019\u001b[39m, \u001b[38;5;241m2026\u001b[39m)\n\u001b[0;32m      3\u001b[0m point2 \u001b[38;5;241m=\u001b[39m second_half_backtest(match_data, Settings(\u001b[38;5;241m0.2\u001b[39m,\u001b[38;5;241m0.1\u001b[39m), team_idx, \u001b[38;5;241m2019\u001b[39m, \u001b[38;5;241m2026\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m point3 \u001b[38;5;241m=\u001b[39m second_half_backtest(match_data, Settings(\u001b[38;5;241m0.3\u001b[39m,\u001b[38;5;241m0.1\u001b[39m), team_idx, \u001b[38;5;241m2018\u001b[39m, \u001b[38;5;241m2026\u001b[39m)\n",
      "Cell \u001b[1;32mIn[30], line 7\u001b[0m, in \u001b[0;36msecond_half_backtest\u001b[1;34m(match_data, settings, team_idx, first, last)\u001b[0m\n\u001b[0;32m      5\u001b[0m     start \u001b[38;5;241m=\u001b[39m date(year, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      6\u001b[0m     end \u001b[38;5;241m=\u001b[39m date(year,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m30\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m     results, pnl \u001b[38;5;241m=\u001b[39m fit_and_backtest(match_data, settings, team_idx, start, end, pnl)\n\u001b[0;32m      8\u001b[0m     mylist\u001b[38;5;241m.\u001b[39mappend(results)\n\u001b[0;32m      9\u001b[0m final \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(mylist)\n",
      "Cell \u001b[1;32mIn[3], line 280\u001b[0m, in \u001b[0;36mfit_and_backtest\u001b[1;34m(match_data, settings, team_idx, test_begin, test_end, init_pnl)\u001b[0m\n\u001b[0;32m    278\u001b[0m n_seasons \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(seasons)\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfitting paramaters on data up to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_begin\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 280\u001b[0m ratings \u001b[38;5;241m=\u001b[39m fit_params(season_matches, n_teams, n_seasons, settings, teams)\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtesting params on data from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_begin\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m until \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_end\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    282\u001b[0m results \u001b[38;5;241m=\u001b[39m backtest(ratings, test, init_pnl)\n",
      "Cell \u001b[1;32mIn[3], line 253\u001b[0m, in \u001b[0;36mfit_params\u001b[1;34m(season_matches, n_teams, n_seasons, settings, teams)\u001b[0m\n\u001b[0;32m    250\u001b[0m theta0 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mn_seasons\u001b[38;5;241m*\u001b[39mn_teams \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    251\u001b[0m theta0[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mh_adv_init\n\u001b[1;32m--> 253\u001b[0m res\u001b[38;5;241m=\u001b[39mminimize(\n\u001b[0;32m    254\u001b[0m     fun\u001b[38;5;241m=\u001b[39mlog_likelihood,\n\u001b[0;32m    255\u001b[0m     x0\u001b[38;5;241m=\u001b[39mtheta0,\n\u001b[0;32m    256\u001b[0m     args\u001b[38;5;241m=\u001b[39m(season_matches,n_teams,settings),\n\u001b[0;32m    257\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL-BFGS-B\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    258\u001b[0m )\n\u001b[0;32m    259\u001b[0m ratings\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mx\n\u001b[0;32m    260\u001b[0m ratings \u001b[38;5;241m=\u001b[39m theta_to_df(ratings, season_matches, teams, n_teams)\n",
      "File \u001b[1;32mc:\\Users\\2468t\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:713\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    710\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    711\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 713\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m    714\u001b[0m                            callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    716\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    717\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32mc:\\Users\\2468t\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:347\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    344\u001b[0m         iprint \u001b[38;5;241m=\u001b[39m disp\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# _prepare_scalar_function can use bounds=None to represent no bounds\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m sf \u001b[38;5;241m=\u001b[39m _prepare_scalar_function(fun, x0, jac\u001b[38;5;241m=\u001b[39mjac, args\u001b[38;5;241m=\u001b[39margs, epsilon\u001b[38;5;241m=\u001b[39meps,\n\u001b[0;32m    348\u001b[0m                               bounds\u001b[38;5;241m=\u001b[39mbounds,\n\u001b[0;32m    349\u001b[0m                               finite_diff_rel_step\u001b[38;5;241m=\u001b[39mfinite_diff_rel_step)\n\u001b[0;32m    351\u001b[0m func_and_grad \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mfun_and_grad\n\u001b[0;32m    353\u001b[0m fortran_int \u001b[38;5;241m=\u001b[39m _lbfgsb\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mintvar\u001b[38;5;241m.\u001b[39mdtype\n",
      "File \u001b[1;32mc:\\Users\\2468t\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:288\u001b[0m, in \u001b[0;36m_prepare_scalar_function\u001b[1;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[0;32m    284\u001b[0m     bounds \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, np\u001b[38;5;241m.\u001b[39minf)\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# calculation reduces overall function evaluations.\u001b[39;00m\n\u001b[1;32m--> 288\u001b[0m sf \u001b[38;5;241m=\u001b[39m ScalarFunction(fun, x0, args, grad, hess,\n\u001b[0;32m    289\u001b[0m                     finite_diff_rel_step, bounds, epsilon\u001b[38;5;241m=\u001b[39mepsilon)\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sf\n",
      "File \u001b[1;32mc:\\Users\\2468t\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:166\u001b[0m, in \u001b[0;36mScalarFunction.__init__\u001b[1;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fun_wrapped(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun_impl \u001b[38;5;241m=\u001b[39m update_fun\n\u001b[1;32m--> 166\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[0;32m    168\u001b[0m \u001b[38;5;66;03m# Gradient evaluation\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(grad):\n",
      "File \u001b[1;32mc:\\Users\\2468t\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:262\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun_impl()\n\u001b[0;32m    263\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\2468t\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:163\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fun_wrapped(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n",
      "File \u001b[1;32mc:\\Users\\2468t\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:145\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 145\u001b[0m fx \u001b[38;5;241m=\u001b[39m fun(np\u001b[38;5;241m.\u001b[39mcopy(x), \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "Cell \u001b[1;32mIn[3], line 108\u001b[0m, in \u001b[0;36mlog_likelihood\u001b[1;34m(big_theta, seasons, n_teams, settings)\u001b[0m\n\u001b[0;32m    103\u001b[0m     nll \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m neg_log_season(theta\u001b[38;5;241m=\u001b[39mtheta, matches_array\u001b[38;5;241m=\u001b[39mmatches, n_teams\u001b[38;5;241m=\u001b[39mn_teams)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# now calculate nll of change in rating between seasons\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# stack all season ratings into array (n_seasons, n_teams)\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m attack_ratings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([big_theta[\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mn_teams\u001b[38;5;241m*\u001b[39mseason:\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mn_teams\u001b[38;5;241m*\u001b[39mseason \u001b[38;5;241m+\u001b[39m n_teams] \u001b[38;5;28;01mfor\u001b[39;00m season \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_seasons)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    109\u001b[0m defence_ratings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([big_theta[\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mn_teams\u001b[38;5;241m*\u001b[39mseason \u001b[38;5;241m+\u001b[39m n_teams : \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mn_teams\u001b[38;5;241m*\u001b[39m(season\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)] \u001b[38;5;28;01mfor\u001b[39;00m season \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_seasons)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# find differences across seasons\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\2468t\\anaconda3\\Lib\\site-packages\\numpy\\core\\shape_base.py:445\u001b[0m, in \u001b[0;36mstack\u001b[1;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[0;32m    443\u001b[0m arrays \u001b[38;5;241m=\u001b[39m [asanyarray(arr) \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m arrays:\n\u001b[1;32m--> 445\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneed at least one array to stack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    447\u001b[0m shapes \u001b[38;5;241m=\u001b[39m {arr\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays}\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shapes) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: need at least one array to stack"
     ]
    }
   ],
   "source": [
    "pointofive = second_half_backtest(match_data, Settings(0.05,0.1), team_idx, 2019, 2026)\n",
    "point1 = second_half_backtest(match_data, Settings(0.1,0.1), team_idx, 2019, 2026)\n",
    "point2 = second_half_backtest(match_data, Settings(0.2,0.1), team_idx, 2019, 2026)\n",
    "point3 = second_half_backtest(match_data, Settings(0.3,0.1), team_idx, 2018, 2026)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3e9a391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting paramaters on data up to 2019-01-01\n",
      "testing params on data from 2019-01-01 until 2019-06-30\n",
      "in this period we made net $12.49\n",
      "\n",
      "fitting paramaters on data up to 2020-01-01\n",
      "testing params on data from 2020-01-01 until 2020-06-30\n",
      "in this period we made net $30.12\n",
      "\n",
      "fitting paramaters on data up to 2021-01-01\n",
      "testing params on data from 2021-01-01 until 2021-06-30\n",
      "in this period we made net $12.04\n",
      "\n",
      "fitting paramaters on data up to 2022-01-01\n",
      "testing params on data from 2022-01-01 until 2022-06-30\n",
      "in this period we made net $13.51\n",
      "\n",
      "fitting paramaters on data up to 2023-01-01\n",
      "testing params on data from 2023-01-01 until 2023-06-30\n",
      "in this period we made net $18.26\n",
      "\n",
      "fitting paramaters on data up to 2024-01-01\n",
      "testing params on data from 2024-01-01 until 2024-06-30\n",
      "in this period we made net $30.21\n",
      "\n",
      "fitting paramaters on data up to 2025-01-01\n",
      "testing params on data from 2025-01-01 until 2025-06-30\n",
      "in this period we made net $-0.62\n",
      "\n",
      "fitting paramaters on data up to 2026-01-01\n",
      "testing params on data from 2026-01-01 until 2026-06-30\n",
      "in this period we made net $5.12\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pnl</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.95</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.07</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.31</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.59</td>\n",
       "      <td>2019-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.78</td>\n",
       "      <td>2019-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>123.13</td>\n",
       "      <td>2026-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>122.13</td>\n",
       "      <td>2026-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>122.13</td>\n",
       "      <td>2026-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>122.13</td>\n",
       "      <td>2026-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>121.13</td>\n",
       "      <td>2026-01-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1352 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pnl        date\n",
       "0     0.95  2019-01-01\n",
       "1     2.07  2019-01-01\n",
       "2     3.31  2019-01-01\n",
       "3     4.59  2019-01-02\n",
       "4     5.78  2019-01-02\n",
       "..     ...         ...\n",
       "38  123.13  2026-01-24\n",
       "39  122.13  2026-01-25\n",
       "40  122.13  2026-01-25\n",
       "41  122.13  2026-01-25\n",
       "42  121.13  2026-01-25\n",
       "\n",
       "[1352 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mylist = []\n",
    "pnl=0\n",
    "for year in range(2019,2027):\n",
    "    start = date(year, 1, 1)\n",
    "    end = date(year,6,30)\n",
    "    results, pnl = fit_and_backtest(match_data, settings, team_idx, start, end, pnl)\n",
    "    mylist.append(results)\n",
    "final = pd.concat(mylist)\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3ca2a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final=pd.concat(mylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfad58b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = fit_params(season_matches, n_teams, n_seasons, Settings(0.1, 0.1), teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "580e893d",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_adv=0.087241"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9460213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratings_to_team_dict(df_ratings: pd.DataFrame, season: int) -> dict[str, Team]:\n",
    "    '''\n",
    "    Convert a ratings dataframe to a dictionary of Team objects for a specific season\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_ratings : pd.DataFrame\n",
    "        DataFrame with columns [\"Season\", \"Team\", \"Attack\", \"Defence\"]\n",
    "    season : int\n",
    "        The season to extract ratings for\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict[str, Team]\n",
    "        Dictionary mapping team name -> Team object\n",
    "    '''\n",
    "    # Filter to the specific season and exclude HomeAdv row\n",
    "    season_ratings = df_ratings[\n",
    "        (df_ratings[\"Season\"] == season) & \n",
    "        (df_ratings[\"Team\"] != \"HomeAdv\")\n",
    "    ]\n",
    "    \n",
    "    # Create dictionary\n",
    "    team_dict = {}\n",
    "    for _, row in season_ratings.iterrows():\n",
    "        team_name = row[\"Team\"]\n",
    "        team_dict[team_name] = Team(\n",
    "            name=team_name,\n",
    "            attack=row[\"Attack\"],\n",
    "            defence=row[\"Defence\"]\n",
    "        )\n",
    "    \n",
    "    return team_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70b82c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_dict = ratings_to_team_dict(ratings_df, 2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55936c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7352046361730764"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/(1-p_total_over(2.5, t_dict[\"Brighton\"],t_dict[\"Everton\"], home_adv))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
